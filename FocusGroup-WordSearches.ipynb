{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Contextual Plus Streams and do text searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, gzip, json, pprint, pymongo, pandas as pd\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENTS = {\n",
    "#     'harvey'      : '/data/chime/Hurricanes_HIM/contextual-plus/OfficialSources_HIM/GNIP/', #HarveyIrma CP\n",
    "#     'matthew'     : '/data/chime/matthew/gnip/',              # This is all keyword collection from Matthew\n",
    "#     'matthew-geo' : '/data/chime/matthew/gnip-geo/all/' # This is all tweets from within the windswath of Matthew\n",
    "    'harvey_kw' : '/data/chime/Hurricanes_HIM/keyword/harvey/GNIP/',\n",
    "    'sandy'  : '/data/chime/sandy_tweets_gnip_simple.jsonl'\n",
    "}\n",
    "\n",
    "START_DATES = {\n",
    "    'sandy': datetime(2012,10,22,0,0,0),\n",
    "    'harvey_kw': datetime(2017,8,17,0,0,0)\n",
    "}\n",
    "\n",
    "END_DATES = {\n",
    "    'sandy': datetime(2012,10,31,0,0,0),\n",
    "    'harvey_kw': datetime(2017,8,27,0,0,0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_tweet(t):\n",
    "    '''Simplify tweet to only specified attributes (e.g. id, text, date, user attributes, etc.)'''\n",
    "    new_tweet = {'id':t['id'].split(':')[2],\n",
    "                 'text':t['body'].replace(\"\\n\",\" \").replace(\"\\r\",\" \").replace(\"\\t\",\" \"),\n",
    "                 'created_at':datetime.strptime(t['postedTime'], \"%Y-%m-%dT%H:%M:%S.%fZ\"),\n",
    "                 'user':t['actor']['preferredUsername'].replace(\"\\t\",\" \"),\n",
    "                 'verb':t['verb']\n",
    "                }        \n",
    "    return(new_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gzip_to_full_tweet(file, event):\n",
    "    tweets          = []\n",
    "    tweet_count     = 0\n",
    "    error_count     = 0\n",
    "    info = None\n",
    "    rt_count = 0\n",
    "    \n",
    "    with gzip.open(file, 'rb') as f:\n",
    "        file_content = f.read()\n",
    "        \n",
    "        for idx, line in enumerate(file_content.decode().split(\"\\n\")):\n",
    "            tweet_count += 1\n",
    "            try:\n",
    "                t = json.loads(line.strip())\n",
    "            except json.JSONDecodeError:\n",
    "                if(line==\"\"):\n",
    "                    pass\n",
    "                \n",
    "            if 'info' in t:\n",
    "                info = t\n",
    "            else:\n",
    "                if t['verb'] != 'share':\n",
    "                    t = simplify_tweet(t)\n",
    "                    if t['created_at'] > START_DATES[event] and t['created_at'] < END_DATES[event]:\n",
    "                        tweets.append(t)\n",
    "                else:\n",
    "                    rt_count+=1\n",
    "\n",
    "            if idx%1000==0:\n",
    "                sys.stderr.write(\"\\r{0} tweets parsed      \".format(tweet_count))\n",
    "#     sys.stderr.write(\"\\r{0} tweets parsed     \".format(tweet_count))\n",
    "    return tweets, info, rt_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(file):\n",
    "    t_count = 0\n",
    "    rt_count = 0\n",
    "    tweet_array = []\n",
    "\n",
    "    with open(file,'r') as inFile:\n",
    "        for line in inFile:\n",
    "            t = json.loads(line)\n",
    "            if t['verb'] != 'share':\n",
    "                t['created_at'] = datetime.strptime(t['created_at'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                tweet_array.append(t)\n",
    "                t_count += 1\n",
    "                if t_count%10000==0:\n",
    "                    sys.stderr.write(\"\\r\"+\" Loaded {0} tweets, skipped {1} retweets\".format(t_count, rt_count))\n",
    "            else: \n",
    "                rt_count += 1\n",
    "    return tweet_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(event, limit=None):\n",
    "    gnip_files = os.listdir( EVENTS[event] )\n",
    "    print(\"Found {0} GNIP files, limit: {1}\".format(len(gnip_files), limit))\n",
    "    \n",
    "    t_count = 0\n",
    "    rt_count_total = 0\n",
    "    tweet_array = []\n",
    "    for idx, file in enumerate(gnip_files[:limit]):\n",
    "        parts = file.split(\"_\")\n",
    "        file_date = datetime(int(parts[1]), int(parts[2]), int(parts[3]), int(parts[4]), int(parts[5]),0)\n",
    "        if file_date < START_DATES[event] or file_date > END_DATES[event]:\n",
    "            continue\n",
    "        \n",
    "        tweets, info, rt_count = gzip_to_full_tweet(EVENTS[event] +file, event)\n",
    "        t_count += info['info']['activity_count']\n",
    "        tweet_array += tweets\n",
    "        rt_count_total += rt_count\n",
    "        if idx%2==0:\n",
    "            sys.stderr.write(\"\\r\"+\" \"*80 + \"{0} files; {1} tweets\".format(idx+1, t_count))\n",
    "    print(\"{0} files processed with {1} tweets, skipped {2} retweets\".format(idx+1, t_count, rt_count_total))\n",
    "    return tweet_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandy Keyword Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Loaded 4840000 tweets, skipped 4175875 retweets"
     ]
    }
   ],
   "source": [
    "sandy_tweets = load_jsonl(EVENTS['sandy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets: 4847095\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>verb</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-24 23:58:06</td>\n",
       "      <td>261255274801815552</td>\n",
       "      <td>New 8PM update from the National Hurricane Cen...</td>\n",
       "      <td>MikeMasco</td>\n",
       "      <td>post</td>\n",
       "      <td>2012-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-24 23:58:07</td>\n",
       "      <td>261255282758402048</td>\n",
       "      <td>Prayers over Jamaica.As Hurricane Sandy approa...</td>\n",
       "      <td>KaiyaNichole</td>\n",
       "      <td>post</td>\n",
       "      <td>2012-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-24 23:58:07</td>\n",
       "      <td>261255281726603266</td>\n",
       "      <td>That T.S turned into a Hurricane in A Few hour...</td>\n",
       "      <td>DJ_BMONEY</td>\n",
       "      <td>post</td>\n",
       "      <td>2012-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-24 23:58:09</td>\n",
       "      <td>261255287581843457</td>\n",
       "      <td>All the news of Hurricane Sandy has left Sandy...</td>\n",
       "      <td>littleritzz</td>\n",
       "      <td>post</td>\n",
       "      <td>2012-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-24 23:58:14</td>\n",
       "      <td>261255312147881985</td>\n",
       "      <td>@mooremayhem  IS A YAAD TING when we get RASS ...</td>\n",
       "      <td>WiggiLeaks</td>\n",
       "      <td>post</td>\n",
       "      <td>2012-10-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at                  id  \\\n",
       "0 2012-10-24 23:58:06  261255274801815552   \n",
       "1 2012-10-24 23:58:07  261255282758402048   \n",
       "2 2012-10-24 23:58:07  261255281726603266   \n",
       "3 2012-10-24 23:58:09  261255287581843457   \n",
       "4 2012-10-24 23:58:14  261255312147881985   \n",
       "\n",
       "                                                text          user  verb  \\\n",
       "0  New 8PM update from the National Hurricane Cen...     MikeMasco  post   \n",
       "1  Prayers over Jamaica.As Hurricane Sandy approa...  KaiyaNichole  post   \n",
       "2  That T.S turned into a Hurricane in A Few hour...     DJ_BMONEY  post   \n",
       "3  All the news of Hurricane Sandy has left Sandy...   littleritzz  post   \n",
       "4  @mooremayhem  IS A YAAD TING when we get RASS ...    WiggiLeaks  post   \n",
       "\n",
       "         date  \n",
       "0  2012-10-24  \n",
       "1  2012-10-24  \n",
       "2  2012-10-24  \n",
       "3  2012-10-24  \n",
       "4  2012-10-24  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SANDY = pd.DataFrame(sandy_tweets)\n",
    "SANDY['date'] = SANDY.created_at.apply(lambda x: x.date())\n",
    "print(\"Tweets: {0}\".format(len(SANDY)))\n",
    "SANDY.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harvey Keyword Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3456 GNIP files, limit: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001 tweets parsed                                                              1905 files; 3149587 tweets"
     ]
    }
   ],
   "source": [
    "harvey_tweets = get_tweets('harvey_kw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HARVEY = pd.DataFrame(harvey_tweets)\n",
    "HARVEY['date'] = HARVEY.created_at.apply(lambda x: x.date())\n",
    "print(\"Tweets: {0}\".format(len(HARVEY)))\n",
    "HARVEY.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some DataFrame Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANDY_WORDS  = ['flooded','sandy','evacuate','electricity','shelter','destroy','generators','light','power','emergency ','candles','flashlights','decisions','disaster','forecast','wind','repair','scary','heat','school ','worried ','response','hospital','rising','substations','government','meetings','population','resources','mayor','receding','relatives','supplies','leaders','looting','transportation','waves','fires','rain','abandoned','devastated','drowned','ocean','raised','rescue','safe','stuck','suffering','survivied','afraid','bridge','designated','impact','neighborhood','rebuild','scared','telephone','twitter','dangerous','federal','firefighters','floated','grid','risk','scientist','terrible','tornado','trouble','administration','announce','authorities','bags','bathtubs','batteries','dumping','fuel','pouring','residents','roof','ambulences','canal','coastal','death','died','donate','garbage','governer','infrastructure','facebook','media','paper','television','computer','cell','internet']\n",
    "HARVEY_WORDS = ['water','helps','community','storm','call','prepared','hurricane','rains','stay','phone','talking','evacuate','homes','news','leave','rescue','tornado','boat','family','church','neighbor','media','fema','bayou','warnings','facebook','weather','emergency','lights','radio','plans','money','power','channel','wind','damage','forecast','decision','shelter','devastation','alerts','gulf','police','rita','cell','lake','seniors','rising','stuck','drain','electricity','drainage','governments','safe','decide','higher','officials','afraid','danger','katrina','mayor','rainfall','surge','trapped','deep','disabled','leaders','strong','bayous','blessed','hospital','praying','frustrating','mexican','risk','river','univision','generator','safety','tide','agency','disaster','faith','mandatory','medicine','reservoirs','hotel','levies','pets','stranded','underwater']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANDY['keywords']  = SANDY.text.apply(lambda text: pd.Series([x in text.lower() for x in SANDY_WORDS]).any())\n",
    "HARVEY['keywords'] = HARVEY.text.apply(lambda text: pd.Series([x in text.lower() for x in HARVEY_WORDS]).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANDY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HARVEY.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary Search Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCIAL_NETWORKS = ['help','mother','father','brother','sister','grandmother','grandfather','neighbor ','friend','community','church','school ','pastor','principal','kids','cousin','neice ','nephew','son ','daughter','aunt','uncle','teacher','neighborhood','children','manager','stuck','aid','assist','grandma','grandpa','family']\n",
    "FORECAST_INFO   = ['flood','rain','surge','wind','water','cone','dirty side','clean side','uncertainty','intensify','landfall','category','forecast','pressure','hurricane','trajectory','tropical','disturbance','depression','tv','radio','internet','paper']\n",
    "PROTECTIVE_DECISIONS = ['stay','leave','shelter','ride','evacuate','roof','higher','attic','get out','rob','theives','pet','dog','cat','motel','hotel','traffic','highway','road','vacancy','go','shutters','elevator','power','electricity','order','mayor','car','subway','bus','basement','last time','shelter']\n",
    "MATERIAL_NEEDS = ['stay','leave','shelter','ride','evacuate','roof','higher','attic','get out','rob','theives','pet','dog','cat','motel','hotel','traffic','highway','road','vacancy','go','shutters','elevator','power','electricity','order','mayor','car','subway','bus','basement','last time','shelter']\n",
    "BEAUROCRATIC_ASSISTANCE = ['papers','fema','red cross','city','Super neighborhood','county','emergency manager','police','fire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_level_search(df):\n",
    "    df['SOCIAL_NETWORKS'] = df.text.apply(lambda text: pd.Series([x in text.lower() for x in SOCIAL_NETWORKS]).any())\n",
    "    df['FORECAST_INFO'] = df.text.apply(lambda text: pd.Series([x in text.lower() for x in FORECAST_INFO]).any())\n",
    "    df['PROTECTIVE_DECISIONS'] = df.text.apply(lambda text: pd.Series([x in text.lower() for x in PROTECTIVE_DECISIONS]).any())\n",
    "    df['MATERIAL_NEEDS'] = df.text.apply(lambda text: pd.Series([x in text.lower() for x in MATERIAL_NEEDS]).any())\n",
    "    df['BEAUROCRATIC_ASSISTANCE'] = df.text.apply(lambda text: pd.Series([x in text.lower() for x in BEAUROCRATIC_ASSISTANCE]).any())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_search(SANDY)\n",
    "second_level_search(HARVEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4847095\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>verb</th>\n",
       "      <th>date</th>\n",
       "      <th>keywords</th>\n",
       "      <th>SOCIAL_NETWORKS</th>\n",
       "      <th>FORECAST_INFO</th>\n",
       "      <th>PROTECTIVE_DECISIONS</th>\n",
       "      <th>MATERIAL_NEEDS</th>\n",
       "      <th>BEAUROCRATIC_ASSISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-24 23:58:06</td>\n",
       "      <td>261255274801815552</td>\n",
       "      <td>New 8PM update from the National Hurricane Cen...</td>\n",
       "      <td>MikeMasco</td>\n",
       "      <td>post</td>\n",
       "      <td>2012-10-24</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-24 23:58:07</td>\n",
       "      <td>261255282758402048</td>\n",
       "      <td>Prayers over Jamaica.As Hurricane Sandy approa...</td>\n",
       "      <td>KaiyaNichole</td>\n",
       "      <td>post</td>\n",
       "      <td>2012-10-24</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-24 23:58:07</td>\n",
       "      <td>261255281726603266</td>\n",
       "      <td>That T.S turned into a Hurricane in A Few hour...</td>\n",
       "      <td>DJ_BMONEY</td>\n",
       "      <td>post</td>\n",
       "      <td>2012-10-24</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-24 23:58:09</td>\n",
       "      <td>261255287581843457</td>\n",
       "      <td>All the news of Hurricane Sandy has left Sandy...</td>\n",
       "      <td>littleritzz</td>\n",
       "      <td>post</td>\n",
       "      <td>2012-10-24</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-24 23:58:14</td>\n",
       "      <td>261255312147881985</td>\n",
       "      <td>@mooremayhem  IS A YAAD TING when we get RASS ...</td>\n",
       "      <td>WiggiLeaks</td>\n",
       "      <td>post</td>\n",
       "      <td>2012-10-24</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at                  id  \\\n",
       "0 2012-10-24 23:58:06  261255274801815552   \n",
       "1 2012-10-24 23:58:07  261255282758402048   \n",
       "2 2012-10-24 23:58:07  261255281726603266   \n",
       "3 2012-10-24 23:58:09  261255287581843457   \n",
       "4 2012-10-24 23:58:14  261255312147881985   \n",
       "\n",
       "                                                text          user  verb  \\\n",
       "0  New 8PM update from the National Hurricane Cen...     MikeMasco  post   \n",
       "1  Prayers over Jamaica.As Hurricane Sandy approa...  KaiyaNichole  post   \n",
       "2  That T.S turned into a Hurricane in A Few hour...     DJ_BMONEY  post   \n",
       "3  All the news of Hurricane Sandy has left Sandy...   littleritzz  post   \n",
       "4  @mooremayhem  IS A YAAD TING when we get RASS ...    WiggiLeaks  post   \n",
       "\n",
       "         date  keywords  SOCIAL_NETWORKS  FORECAST_INFO  PROTECTIVE_DECISIONS  \\\n",
       "0  2012-10-24      True            False           True                  True   \n",
       "1  2012-10-24      True             True           True                 False   \n",
       "2  2012-10-24     False            False           True                 False   \n",
       "3  2012-10-24      True             True           True                 False   \n",
       "4  2012-10-24      True             True           True                  True   \n",
       "\n",
       "   MATERIAL_NEEDS  BEAUROCRATIC_ASSISTANCE  \n",
       "0            True                    False  \n",
       "1           False                    False  \n",
       "2           False                    False  \n",
       "3           False                    False  \n",
       "4            True                    False  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(SANDY))\n",
    "SANDY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1416755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>verb</th>\n",
       "      <th>date</th>\n",
       "      <th>keywords</th>\n",
       "      <th>SOCIAL_NETWORKS</th>\n",
       "      <th>FORECAST_INFO</th>\n",
       "      <th>PROTECTIVE_DECISIONS</th>\n",
       "      <th>MATERIAL_NEEDS</th>\n",
       "      <th>BEAUROCRATIC_ASSISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-23 18:00:00</td>\n",
       "      <td>900417352453373953</td>\n",
       "      <td>Sarah Harvey talks about Harvey Lawrence – whe...</td>\n",
       "      <td>harveylawrence</td>\n",
       "      <td>post</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-23 18:00:04</td>\n",
       "      <td>900417371080347650</td>\n",
       "      <td>If you live along the Gulf Coast, stay safe an...</td>\n",
       "      <td>gacarol18</td>\n",
       "      <td>post</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-23 18:00:14</td>\n",
       "      <td>900417412117536768</td>\n",
       "      <td>New post (Harvey Could Become First Hurricane ...</td>\n",
       "      <td>kilocals</td>\n",
       "      <td>post</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-23 18:00:15</td>\n",
       "      <td>900417416911626240</td>\n",
       "      <td>Nike Mens Sportswear Pull Over Club Hooded Swe...</td>\n",
       "      <td>USA_OnlineDeals</td>\n",
       "      <td>post</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-23 18:00:59</td>\n",
       "      <td>900417598722121728</td>\n",
       "      <td>I'm pretty sure the mall will stay open during...</td>\n",
       "      <td>charityemmite</td>\n",
       "      <td>post</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at                  id  \\\n",
       "0 2017-08-23 18:00:00  900417352453373953   \n",
       "1 2017-08-23 18:00:04  900417371080347650   \n",
       "2 2017-08-23 18:00:14  900417412117536768   \n",
       "3 2017-08-23 18:00:15  900417416911626240   \n",
       "4 2017-08-23 18:00:59  900417598722121728   \n",
       "\n",
       "                                                text             user  verb  \\\n",
       "0  Sarah Harvey talks about Harvey Lawrence – whe...   harveylawrence  post   \n",
       "1  If you live along the Gulf Coast, stay safe an...        gacarol18  post   \n",
       "2  New post (Harvey Could Become First Hurricane ...         kilocals  post   \n",
       "3  Nike Mens Sportswear Pull Over Club Hooded Swe...  USA_OnlineDeals  post   \n",
       "4  I'm pretty sure the mall will stay open during...    charityemmite  post   \n",
       "\n",
       "         date  keywords  SOCIAL_NETWORKS  FORECAST_INFO  PROTECTIVE_DECISIONS  \\\n",
       "0  2017-08-23     False            False          False                  True   \n",
       "1  2017-08-23      True            False          False                  True   \n",
       "2  2017-08-23      True            False           True                 False   \n",
       "3  2017-08-23     False            False          False                 False   \n",
       "4  2017-08-23      True            False           True                  True   \n",
       "\n",
       "   MATERIAL_NEEDS  BEAUROCRATIC_ASSISTANCE  \n",
       "0            True                    False  \n",
       "1            True                    False  \n",
       "2           False                    False  \n",
       "3           False                    False  \n",
       "4            True                    False  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(HARVEY))\n",
    "HARVEY.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "# 2. Group the dataframes by user \n",
    "Get counts for tweets within the second level filtering to identify users of most interest? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "HARVEY_gb_user = HARVEY.groupby('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANDY_gb_user = SANDY.groupby('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interesting_users(DF_gb_user, threshold=10):\n",
    "    USERS_SN = []\n",
    "    USERS_FI = []\n",
    "    USERS_PD = []\n",
    "    USERS_MN = []\n",
    "    USERS_BA = []\n",
    "    \n",
    "    count = 0;\n",
    "\n",
    "    for user, tweets in DF_gb_user:\n",
    "    #     if tweets.keywords.any():\n",
    "        if tweets.SOCIAL_NETWORKS.sum() > threshold:\n",
    "            USERS_SN.append( (user, tweets.SOCIAL_NETWORKS.sum() ) )\n",
    "        if tweets.FORECAST_INFO.sum() > threshold:\n",
    "            USERS_FI.append( (user, tweets.FORECAST_INFO.sum() ) )\n",
    "        if tweets.PROTECTIVE_DECISIONS.sum() > threshold:\n",
    "            USERS_PD.append( (user, tweets.PROTECTIVE_DECISIONS.sum() ) )\n",
    "        if tweets.MATERIAL_NEEDS.sum() > threshold:\n",
    "            USERS_MN.append( (user, tweets.MATERIAL_NEEDS.sum() ) )\n",
    "        if tweets.BEAUROCRATIC_ASSISTANCE.sum() > threshold:\n",
    "            USERS_BA.append( (user, tweets.BEAUROCRATIC_ASSISTANCE.sum() ) )\n",
    "\n",
    "        count+=1\n",
    "        if count%100==0:\n",
    "            sys.stderr.write(\"\\r\"+\" Processed {0} users\".format(count))\n",
    "\n",
    "    return {\n",
    "        'social_networks' : USERS_SN,\n",
    "        'forecast_info' : USERS_FI,\n",
    "        'protective_decisions' : USERS_PD,\n",
    "        'material_needs' : USERS_MN,\n",
    "        'beaurocratic_assistance' : USERS_BA\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Processed 612800 users"
     ]
    }
   ],
   "source": [
    "harvey_users = find_interesting_users(HARVEY_gb_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Processed 28900 users"
     ]
    }
   ],
   "source": [
    "sandy_users = find_interesting_users(SANDY_gb_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Social Networks (Sandy)' : [x[1] for x in sandy_users['social_networks']]}).hist(bins=[1,2,3,4,5,6,7,8,10,100,200,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
